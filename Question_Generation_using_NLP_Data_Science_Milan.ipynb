{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Generation using NLP - Data Science Milan.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GfI2_yZVjWOk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVsqmcx5IOfg"
      },
      "source": [
        "## Author of this notebook : Ramsri Goutham Golla\n",
        "\n",
        "Linkedin: https://www.linkedin.com/in/ramsrig/\n",
        "\n",
        "Twitter : https://twitter.com/ramsri_goutham\n",
        "\n",
        "Udemy Course: **[Question generation using NLP Course](https://www.udemy.com/course/question-generation-using-natural-language-processing/?referralCode=C8EA86A28F5398CBF763)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpcTL4f2G9WE"
      },
      "source": [
        "## Installation of libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM2h7czt2s0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34f22f8-4c62-4a24-a088-8bcdb5de7b24"
      },
      "source": [
        "!pip install --quiet transformers==4.5.0\n",
        "!pip install --quiet sentencepiece==0.1.95\n",
        "!pip install --quiet textwrap3==0.9.2\n",
        "!pip install --quiet nltk==3.2.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.98 s (started: 2021-05-20 17:00:04 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDHhiuKJ2eva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd948c3b-bfa8-4311-8e1a-8214fc5ae88e"
      },
      "source": [
        "!pip install --quiet ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 2.5 s (started: 2021-05-20 17:00:14 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVBDYRGTAW7"
      },
      "source": [
        "## Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRNhJ0wPn_kv"
      },
      "source": [
        "Text taken from: \n",
        "https://gadgets.ndtv.com/internet/news/dogecoin-price-rally-surge-elon-musk-tweet-twitter-working-developers-improve-transaction-efficiency-2442120"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt5wyqeq0Pq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e176ddc9-2698-41ec-d1b9-18b0698afc7e"
      },
      "source": [
        "from textwrap3 import wrap\n",
        "\n",
        "text = \"\"\"Elon Musk has shown again he can influence the digital currency market with just his tweets. After saying that his electric vehicle-making company\n",
        "Tesla will not accept payments in Bitcoin because of environmental concerns, he tweeted that he was working with developers of Dogecoin to improve\n",
        "system transaction efficiency. Following the two distinct statements from him, the world's largest cryptocurrency hit a two-month low, while Dogecoin\n",
        "rallied by about 20 percent. The SpaceX CEO has in recent months often tweeted in support of Dogecoin, but rarely for Bitcoin.  In a recent tweet,\n",
        "Musk put out a statement from Tesla that it was “concerned” about the rapidly increasing use of fossil fuels for Bitcoin (price in India) mining and\n",
        "transaction, and hence was suspending vehicle purchases using the cryptocurrency.  A day later he again tweeted saying, “To be clear, I strongly\n",
        "believe in crypto, but it can't drive a massive increase in fossil fuel use, especially coal”.  It triggered a downward spiral for Bitcoin value but\n",
        "the cryptocurrency has stabilised since.   A number of Twitter users welcomed Musk's statement. One of them said it's time people started realising\n",
        "that Dogecoin “is here to stay” and another referred to Musk's previous assertion that crypto could become the world's future currency.\"\"\"\n",
        "\n",
        "for wrp in wrap(text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elon Musk has shown again he can influence the digital currency market with just his tweets. After saying that his electric vehicle-making company\n",
            "Tesla will not accept payments in Bitcoin because of environmental concerns, he tweeted that he was working with developers of Dogecoin to improve\n",
            "system transaction efficiency. Following the two distinct statements from him, the world's largest cryptocurrency hit a two-month low, while Dogecoin\n",
            "rallied by about 20 percent. The SpaceX CEO has in recent months often tweeted in support of Dogecoin, but rarely for Bitcoin.  In a recent tweet,\n",
            "Musk put out a statement from Tesla that it was “concerned” about the rapidly increasing use of fossil fuels for Bitcoin (price in India) mining and\n",
            "transaction, and hence was suspending vehicle purchases using the cryptocurrency.  A day later he again tweeted saying, “To be clear, I strongly\n",
            "believe in crypto, but it can't drive a massive increase in fossil fuel use, especially coal”.  It triggered a downward spiral for Bitcoin value but\n",
            "the cryptocurrency has stabilised since.   A number of Twitter users welcomed Musk's statement. One of them said it's time people started realising\n",
            "that Dogecoin “is here to stay” and another referred to Musk's previous assertion that crypto could become the world's future currency.\n",
            "\n",
            "\n",
            "time: 4.75 ms (started: 2021-05-20 17:00:55 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VOdyZg2rBP1"
      },
      "source": [
        "Musk tweeted that his electric vehicle-making company tesla will not accept payments in bitcoin because of environmental concerns. He also said that\n",
        "the company was working with developers of dogecoin to improve system transaction efficiency. The world's largest cryptocurrency hit a two-month low,\n",
        "while doge coin rallied by about 20 percent. Musk has in recent months often tweeted in support of crypto, but rarely for bitcoin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScrtI0ueTFbR"
      },
      "source": [
        "## Example 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sHMJ5ubS5Gf"
      },
      "source": [
        "http://read.gov/aesop/007.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrMhx6BAP2Ez"
      },
      "source": [
        "text = \"\"\"A Lion lay asleep in the forest, his great head resting on his paws. A timid little Mouse came upon him unexpectedly, and in her fright and haste to\n",
        "get away, ran across the Lion's nose. Roused from his nap, the Lion laid his huge paw angrily on the tiny creature to kill her.  \"Spare me!\" begged\n",
        "the poor Mouse. \"Please let me go and some day I will surely repay you.\"  The Lion was much amused to think that a Mouse could ever help him. But he\n",
        "was generous and finally let the Mouse go.  Some days later, while stalking his prey in the forest, the Lion was caught in the toils of a hunter's\n",
        "net. Unable to free himself, he filled the forest with his angry roaring. The Mouse knew the voice and quickly found the Lion struggling in the net.\n",
        "Running to one of the great ropes that bound him, she gnawed it until it parted, and soon the Lion was free.  \"You laughed when I said I would repay\n",
        "you,\" said the Mouse. \"Now you see that even a Mouse can help a Lion.\" \"\"\"\n",
        "for wrp in wrap(text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imbR470g15Fq"
      },
      "source": [
        "# **Summarization with T5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cXs7fnvCarm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc1982a-7301-4bf8-a0d5-241d1872f6e6"
      },
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "summary_model = summary_model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 20.9 s (started: 2021-05-20 17:02:02 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzGsTUJ8TyAN",
        "outputId": "7742b4f6-7aad-422a-9b9d-6d033ebc3eb6"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.71 ms (started: 2021-05-20 17:02:25 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JaEy5Xw_UMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dce004-255d-4741-c505-c22a3d78dede"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def postprocesstext (content):\n",
        "  final=\"\"\n",
        "  for sent in sent_tokenize(content):\n",
        "    sent = sent.capitalize()\n",
        "    final = final +\" \"+sent\n",
        "  return final\n",
        "\n",
        "\n",
        "def summarizer(text,model,tokenizer):\n",
        "  text = text.strip().replace(\"\\n\",\" \")\n",
        "  text = \"summarize: \"+text\n",
        "  # print (text)\n",
        "  max_len = 512\n",
        "  encoding = tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = model.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=3,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  min_length = 75,\n",
        "                                  max_length=300)\n",
        "\n",
        "\n",
        "  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "  summary = dec[0]\n",
        "  summary = postprocesstext(summary)\n",
        "  summary= summary.strip()\n",
        "\n",
        "  return summary\n",
        "\n",
        "\n",
        "summarized_text = summarizer(text,summary_model,summary_tokenizer)\n",
        "\n",
        "\n",
        "print (\"\\noriginal Text >>\")\n",
        "for wrp in wrap(text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")\n",
        "print (\"Summarized Text >>\")\n",
        "for wrp in wrap(summarized_text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "\n",
            "original Text >>\n",
            "Elon Musk has shown again he can influence the digital currency market with just his tweets. After saying that his electric vehicle-making company\n",
            "Tesla will not accept payments in Bitcoin because of environmental concerns, he tweeted that he was working with developers of Dogecoin to improve\n",
            "system transaction efficiency. Following the two distinct statements from him, the world's largest cryptocurrency hit a two-month low, while Dogecoin\n",
            "rallied by about 20 percent. The SpaceX CEO has in recent months often tweeted in support of Dogecoin, but rarely for Bitcoin.  In a recent tweet,\n",
            "Musk put out a statement from Tesla that it was “concerned” about the rapidly increasing use of fossil fuels for Bitcoin (price in India) mining and\n",
            "transaction, and hence was suspending vehicle purchases using the cryptocurrency.  A day later he again tweeted saying, “To be clear, I strongly\n",
            "believe in crypto, but it can't drive a massive increase in fossil fuel use, especially coal”.  It triggered a downward spiral for Bitcoin value but\n",
            "the cryptocurrency has stabilised since.   A number of Twitter users welcomed Musk's statement. One of them said it's time people started realising\n",
            "that Dogecoin “is here to stay” and another referred to Musk's previous assertion that crypto could become the world's future currency.\n",
            "\n",
            "\n",
            "Summarized Text >>\n",
            "Musk tweeted that his electric vehicle-making company tesla will not accept payments in bitcoin because of environmental concerns. He also said that\n",
            "the company was working with developers of dogecoin to improve system transaction efficiency. The world's largest cryptocurrency hit a two-month low,\n",
            "while doge coin rallied by about 20 percent. Musk has in recent months often tweeted in support of crypto, but rarely for bitcoin.\n",
            "\n",
            "\n",
            "time: 1.89 s (started: 2021-05-20 17:02:29 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0YrWTxQCo9q"
      },
      "source": [
        "# **Answer Span Extraction (Keywords and Noun Phrases)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9TmL5LR2Ucg",
        "outputId": "8f38b092-f2aa-4f2b-c6a9-7a259dccaadd"
      },
      "source": [
        "!pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n",
        "!pip install --quiet flashtext==2.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "time: 11.8 s (started: 2021-05-20 17:04:38 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DxJGFn4MfD"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import pke\n",
        "import traceback\n",
        "\n",
        "def get_nouns_multipartite(content):\n",
        "    out=[]\n",
        "    try:\n",
        "        extractor = pke.unsupervised.MultipartiteRank()\n",
        "        extractor.load_document(input=content)\n",
        "        #    not contain punctuation marks or stopwords as candidates.\n",
        "        pos = {'PROPN','NOUN'}\n",
        "        #pos = {'PROPN','NOUN'}\n",
        "        stoplist = list(string.punctuation)\n",
        "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "        stoplist += stopwords.words('english')\n",
        "        extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "        # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "        #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "        #    threshold/method parameters.\n",
        "        extractor.candidate_weighting(alpha=1.1,\n",
        "                                      threshold=0.75,\n",
        "                                      method='average')\n",
        "        keyphrases = extractor.get_n_best(n=15)\n",
        "        \n",
        "\n",
        "        for val in keyphrases:\n",
        "            out.append(val[0])\n",
        "    except:\n",
        "        out = []\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_sRWHAd4Wwp",
        "outputId": "46fa79f7-a526-4e0d-b120-84f350bdb151"
      },
      "source": [
        "from flashtext import KeywordProcessor\n",
        "\n",
        "\n",
        "def get_keywords(originaltext,summarytext):\n",
        "  keywords = get_nouns_multipartite(originaltext)\n",
        "  print (\"keywords unsummarized: \",keywords)\n",
        "  keyword_processor = KeywordProcessor()\n",
        "  for keyword in keywords:\n",
        "    keyword_processor.add_keyword(keyword)\n",
        "\n",
        "  keywords_found = keyword_processor.extract_keywords(summarytext)\n",
        "  keywords_found = list(set(keywords_found))\n",
        "  print (\"keywords_found in summarized: \",keywords_found)\n",
        "\n",
        "  important_keywords =[]\n",
        "  for keyword in keywords:\n",
        "    if keyword in keywords_found:\n",
        "      important_keywords.append(keyword)\n",
        "\n",
        "  return important_keywords[:4]\n",
        "\n",
        "\n",
        "imp_keywords = get_keywords(text,summarized_text)\n",
        "print (imp_keywords)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keywords unsummarized:  ['elon musk', 'bitcoin', 'dogecoin', 'statements', 'tesla', 'tweets', 'cryptocurrency', 'vehicle', 'musk', 'system transaction efficiency', 'currency market', 'month low', 'fuels', 'company', 'world']\n",
            "keywords_found in summarized:  ['dogecoin', 'month low', 'world', 'tesla', 'company', 'system transaction efficiency', 'vehicle', 'cryptocurrency', 'musk', 'bitcoin']\n",
            "['bitcoin', 'dogecoin', 'tesla', 'cryptocurrency']\n",
            "time: 753 ms (started: 2021-05-20 17:05:48 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXbq7b2WCaZ_"
      },
      "source": [
        "# **Question generation with T5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CuKlpL1Cj6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e744880-11a2-4274-db38-4ec7dceaff69"
      },
      "source": [
        "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_model = question_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 8.2 s (started: 2021-05-20 17:08:47 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uzA4uLJ_P48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "845d9e57-74ac-43cc-ca8b-c6a6f13c3d35"
      },
      "source": [
        "def get_question(context,answer,model,tokenizer):\n",
        "  text = \"context: {} answer: {}\".format(context,answer)\n",
        "  encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = model.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=72)\n",
        "\n",
        "\n",
        "  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "\n",
        "\n",
        "  Question = dec[0].replace(\"question:\",\"\")\n",
        "  Question= Question.strip()\n",
        "  return Question\n",
        "\n",
        "\n",
        "\n",
        "for wrp in wrap(summarized_text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")\n",
        "\n",
        "for answer in imp_keywords:\n",
        "  ques = get_question(summarized_text,answer,question_model,question_tokenizer)\n",
        "  print (ques)\n",
        "  print (answer.capitalize())\n",
        "  print (\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Musk tweeted that his electric vehicle-making company tesla will not accept payments in bitcoin because of environmental concerns. He also said that\n",
            "the company was working with developers of dogecoin to improve system transaction efficiency. The world's largest cryptocurrency hit a two-month low,\n",
            "while doge coin rallied by about 20 percent. Musk has in recent months often tweeted in support of crypto, but rarely for bitcoin.\n",
            "\n",
            "\n",
            "What cryptocurrency did Musk rarely tweet about?\n",
            "Bitcoin\n",
            "\n",
            "\n",
            "What did Musk say he was working with to improve system transaction efficiency?\n",
            "Dogecoin\n",
            "\n",
            "\n",
            "What company did Musk say would not accept bitcoin payments?\n",
            "Tesla\n",
            "\n",
            "\n",
            "What has Musk often tweeted in support of?\n",
            "Cryptocurrency\n",
            "\n",
            "\n",
            "time: 1.04 s (started: 2021-05-20 17:09:00 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfI2_yZVjWOk"
      },
      "source": [
        "# **Gradio UI Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr03_LUKjdTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4cf8bbd-b78a-4045-bbf5-4fccd00df285"
      },
      "source": [
        "!pip install --quiet gradio==1.6.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.62 s (started: 2021-05-20 17:10:51 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ti0nc9kjsfh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a40fce44-b1ba-4ca0-dc8a-5a375d1296df"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "context = gr.inputs.Textbox(lines=10, placeholder=\"Enter paragraph/content here...\")\n",
        "output = gr.outputs.HTML(  label=\"Question and Answers\")\n",
        "\n",
        "\n",
        "def generate_question(context):\n",
        "  summary_text = summarizer(context,summary_model,summary_tokenizer)\n",
        "  for wrp in wrap(summary_text, 150):\n",
        "    print (wrp)\n",
        "  np =  get_keywords(context,summary_text)\n",
        "  print (\"\\n\\nNoun phrases\",np)\n",
        "  output=\"\"\n",
        "  for answer in np:\n",
        "    ques = get_question(summary_text,answer,question_model,question_tokenizer)\n",
        "    # output= output + ques + \"\\n\" + \"Ans: \"+answer.capitalize() + \"\\n\\n\"\n",
        "    output = output + \"<b style='color:blue;'>\" + ques + \"</b>\"\n",
        "    # output = output + \"<br>\"\n",
        "    output = output + \"<b style='color:green;'>\" + \"Ans: \" +answer.capitalize()+  \"</b>\"\n",
        "    output = output + \"<br>\"\n",
        "\n",
        "  summary =\"Summary: \"+ summary_text\n",
        "  for answer in np:\n",
        "    summary = summary.replace(answer,\"<b>\"+answer+\"</b>\")\n",
        "    summary = summary.replace(answer.capitalize(),\"<b>\"+answer.capitalize()+\"</b>\")\n",
        "  output = output + \"<p>\"+summary+\"</p>\"\n",
        "  \n",
        "  return output\n",
        "\n",
        "iface = gr.Interface(\n",
        "  fn=generate_question, \n",
        "  inputs=context, \n",
        "  outputs=output)\n",
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://56800.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://56800.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f463e218190>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Musk tweeted that his electric vehicle-making company tesla will not accept payments in bitcoin because of environmental concerns. He also said that\n",
            "the company was working with developers of dogecoin to improve system transaction efficiency. The world's largest cryptocurrency hit a two-month low,\n",
            "while doge coin rallied by about 20 percent. Musk has in recent months often tweeted in support of crypto, but rarely for bitcoin.\n",
            "keywords unsummarized:  ['elon musk', 'bitcoin', 'dogecoin', 'statements', 'tesla', 'tweets', 'cryptocurrency', 'vehicle', 'musk', 'system transaction efficiency', 'currency market', 'month low', 'fuels', 'company', 'world']\n",
            "keywords_found in summarized:  ['dogecoin', 'month low', 'world', 'tesla', 'company', 'system transaction efficiency', 'vehicle', 'cryptocurrency', 'musk', 'bitcoin']\n",
            "\n",
            "\n",
            "Noun phrases ['bitcoin', 'dogecoin', 'tesla', 'cryptocurrency']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-0631ba6db8d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   outputs=output)\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 1min 45s (started: 2021-05-20 17:11:03 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcV4uNlmApdW"
      },
      "source": [
        "# **Filter keywords with Maximum marginal Relevance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asz04PIeQhHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209fc898-c8bf-4e3e-8a69-6c3581e91a4d"
      },
      "source": [
        "!pip install --quiet keybert==0.2.0\n",
        "!pip install --quiet strsim==0.0.3\n",
        "!pip install --quiet sense2vec==1.0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.54 s (started: 2021-05-20 17:13:00 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWi5WM67BLhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a04810-3129-4781-af89-01d6ab66b7e6"
      },
      "source": [
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xvf  s2v_reddit_2015_md.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-20 17:13:38--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210520%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210520T171338Z&X-Amz-Expires=300&X-Amz-Signature=a1ffd17733fcffffc3f90524ec6283be15896b9e58ddba4b53b86327a666ef1d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-05-20 17:13:38--  https://github-releases.githubusercontent.com/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210520%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210520T171338Z&X-Amz-Expires=300&X-Amz-Signature=a1ffd17733fcffffc3f90524ec6283be15896b9e58ddba4b53b86327a666ef1d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz.1’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M  65.1MB/s    in 11s     \n",
            "\n",
            "2021-05-20 17:13:49 (52.8 MB/s) - ‘s2v_reddit_2015_md.tar.gz.1’ saved [600444501/600444501]\n",
            "\n",
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n",
            "time: 20.9 s (started: 2021-05-20 17:13:38 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVBkX2IoBgd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b88f56d-2e3f-4387-c11a-47d4da05673b"
      },
      "source": [
        "import numpy as np\n",
        "from sense2vec import Sense2Vec\n",
        "s2v = Sense2Vec().from_disk('s2v_old')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 6.01 s (started: 2021-05-20 17:13:59 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAqN2OZbQ51Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c413822-a46d-45fb-a97d-655db157324b"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# paraphrase-distilroberta-base-v1\n",
        "sentence_transformer_model = SentenceTransformer('msmarco-distilbert-base-v3')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.68 s (started: 2021-05-20 17:14:05 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv-FoyLEdCGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933a50f2-9bf4-4547-cf99-fa3c8c1a866c"
      },
      "source": [
        "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
        "normalized_levenshtein = NormalizedLevenshtein()\n",
        "\n",
        "def filter_same_sense_words(original,wordlist):\n",
        "  filtered_words=[]\n",
        "  base_sense =original.split('|')[1] \n",
        "  print (base_sense)\n",
        "  for eachword in wordlist:\n",
        "    if eachword[0].split('|')[1] == base_sense:\n",
        "      filtered_words.append(eachword[0].split('|')[0].replace(\"_\", \" \").title().strip())\n",
        "  return filtered_words\n",
        "\n",
        "def get_highest_similarity_score(wordlist,wrd):\n",
        "  score=[]\n",
        "  for each in wordlist:\n",
        "    score.append(normalized_levenshtein.similarity(each.lower(),wrd.lower()))\n",
        "  return max(score)\n",
        "\n",
        "def sense2vec_get_words(word,s2v,topn,question):\n",
        "    output = []\n",
        "    print (\"word \",word)\n",
        "    try:\n",
        "      sense = s2v.get_best_sense(word, senses= [\"NOUN\", \"PERSON\",\"PRODUCT\",\"LOC\",\"ORG\",\"EVENT\",\"NORP\",\"WORK OF ART\",\"FAC\",\"GPE\",\"NUM\",\"FACILITY\"])\n",
        "      most_similar = s2v.most_similar(sense, n=topn)\n",
        "      # print (most_similar)\n",
        "      output = filter_same_sense_words(sense,most_similar)\n",
        "      print (\"Similar \",output)\n",
        "    except:\n",
        "      output =[]\n",
        "\n",
        "    threshold = 0.6\n",
        "    final=[word]\n",
        "    checklist =question.split()\n",
        "    for x in output:\n",
        "      if get_highest_similarity_score(final,x)<threshold and x not in final and x not in checklist:\n",
        "        final.append(x)\n",
        "    \n",
        "    return final[1:]\n",
        "\n",
        "def mmr(doc_embedding, word_embeddings, words, top_n, lambda_param):\n",
        "\n",
        "    # Extract similarity within words, and between words and the document\n",
        "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
        "    word_similarity = cosine_similarity(word_embeddings)\n",
        "\n",
        "    # Initialize candidates and already choose best keyword/keyphrase\n",
        "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
        "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
        "\n",
        "    for _ in range(top_n - 1):\n",
        "        # Extract similarities within candidates and\n",
        "        # between candidates and selected keywords/phrases\n",
        "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
        "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
        "\n",
        "        # Calculate MMR\n",
        "        mmr = (lambda_param) * candidate_similarities - (1-lambda_param) * target_similarities.reshape(-1, 1)\n",
        "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
        "\n",
        "        # Update keywords & candidates\n",
        "        keywords_idx.append(mmr_idx)\n",
        "        candidates_idx.remove(mmr_idx)\n",
        "\n",
        "    return [words[idx] for idx in keywords_idx]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 48 ms (started: 2021-05-20 17:15:16 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eigljekAu9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19c5474-0214-4368-f3ec-fc3a0dde41fc"
      },
      "source": [
        "from collections import OrderedDict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_distractors_wordnet(word):\n",
        "    distractors=[]\n",
        "    try:\n",
        "      syn = wn.synsets(word,'n')[0]\n",
        "      \n",
        "      word= word.lower()\n",
        "      orig_word = word\n",
        "      if len(word.split())>0:\n",
        "          word = word.replace(\" \",\"_\")\n",
        "      hypernym = syn.hypernyms()\n",
        "      if len(hypernym) == 0: \n",
        "          return distractors\n",
        "      for item in hypernym[0].hyponyms():\n",
        "          name = item.lemmas()[0].name()\n",
        "          #print (\"name \",name, \" word\",orig_word)\n",
        "          if name == orig_word:\n",
        "              continue\n",
        "          name = name.replace(\"_\",\" \")\n",
        "          name = \" \".join(w.capitalize() for w in name.split())\n",
        "          if name is not None and name not in distractors:\n",
        "              distractors.append(name)\n",
        "    except:\n",
        "      print (\"Wordnet distractors not found\")\n",
        "    return distractors\n",
        "\n",
        "def get_distractors (word,origsentence,sense2vecmodel,sentencemodel,top_n,lambdaval):\n",
        "  distractors = sense2vec_get_words(word,sense2vecmodel,top_n,origsentence)\n",
        "  print (\"distractors \",distractors)\n",
        "  if len(distractors) ==0:\n",
        "    return distractors\n",
        "  distractors_new = [word.capitalize()]\n",
        "  distractors_new.extend(distractors)\n",
        "  # print (\"distractors_new .. \",distractors_new)\n",
        "\n",
        "  embedding_sentence = origsentence+ \" \"+word.capitalize()\n",
        "  # embedding_sentence = word\n",
        "  keyword_embedding = sentencemodel.encode([embedding_sentence])\n",
        "  distractor_embeddings = sentencemodel.encode(distractors_new)\n",
        "\n",
        "  # filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors,4,0.7)\n",
        "  max_keywords = min(len(distractors_new),5)\n",
        "  filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors_new,max_keywords,lambdaval)\n",
        "  # filtered_keywords = filtered_keywords[1:]\n",
        "  final = [word.capitalize()]\n",
        "  for wrd in filtered_keywords:\n",
        "    if wrd.lower() !=word.lower():\n",
        "      final.append(wrd.capitalize())\n",
        "  final = final[1:]\n",
        "  return final\n",
        "\n",
        "sent = \"What cryptocurrency did Musk rarely tweet about?\"\n",
        "keyword = \"Bitcoin\"\n",
        "\n",
        "# sent = \"What did Musk say he was working with to improve system transaction efficiency?\"\n",
        "# keyword= \"Dogecoin\"\n",
        "\n",
        "\n",
        "# sent = \"What company did Musk say would not accept bitcoin payments?\"\n",
        "# keyword= \"Tesla\"\n",
        "\n",
        "\n",
        "# sent = \"What has Musk often tweeted in support of?\"\n",
        "# keyword = \"Cryptocurrency\"\n",
        "\n",
        "print (get_distractors(keyword,sent,s2v,sentence_transformer_model,40,0.2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word  Bitcoin\n",
            "PERSON\n",
            "Similar  ['Litecoin', 'Bitcoins', 'Dogecoin', 'Bitcoin', 'Coinbase']\n",
            "distractors  ['Dogecoin', 'Coinbase']\n",
            "['Dogecoin', 'Coinbase']\n",
            "time: 713 ms (started: 2021-05-20 17:15:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogiuJdRgg7V6"
      },
      "source": [
        "# **Gradio Visualization with MCQs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC0i2ECThAqW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97a6402b-e132-44f7-ec85-981d1f937a81"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "context = gr.inputs.Textbox(lines=10, placeholder=\"Enter paragraph/content here...\")\n",
        "output = gr.outputs.HTML(  label=\"Question and Answers\")\n",
        "radiobutton = gr.inputs.Radio([\"Wordnet\", \"Sense2Vec\"])\n",
        "\n",
        "def generate_question(context,radiobutton):\n",
        "  summary_text = summarizer(context,summary_model,summary_tokenizer)\n",
        "  for wrp in wrap(summary_text, 150):\n",
        "    print (wrp)\n",
        "  # np = getnounphrases(summary_text,sentence_transformer_model,3)\n",
        "  np =  get_keywords(context,summary_text)\n",
        "  print (\"\\n\\nNoun phrases\",np)\n",
        "  output=\"\"\n",
        "  for answer in np:\n",
        "    ques = get_question(summary_text,answer,question_model,question_tokenizer)\n",
        "    if radiobutton==\"Wordnet\":\n",
        "      distractors = get_distractors_wordnet(answer)\n",
        "    else:\n",
        "      distractors = get_distractors(answer.capitalize(),ques,s2v,sentence_transformer_model,40,0.2)\n",
        "    # output= output + ques + \"\\n\" + \"Ans: \"+answer.capitalize() + \"\\n\\n\"\n",
        "    output = output + \"<b style='color:blue;'>\" + ques + \"</b>\"\n",
        "    # output = output + \"<br>\"\n",
        "    output = output + \"<b style='color:green;'>\" + \"Ans: \" +answer.capitalize()+  \"</b>\"\n",
        "    if len(distractors)>0:\n",
        "      for distractor in distractors[:4]:\n",
        "        output = output + \"<b style='color:brown;'>\" + distractor+  \"</b>\"\n",
        "    output = output + \"<br>\"\n",
        "\n",
        "  summary =\"Summary: \"+ summary_text\n",
        "  for answer in np:\n",
        "    summary = summary.replace(answer,\"<b>\"+answer+\"</b>\")\n",
        "    summary = summary.replace(answer.capitalize(),\"<b>\"+answer.capitalize()+\"</b>\")\n",
        "  output = output + \"<p>\"+summary+\"</p>\"\n",
        "  return output\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "  fn=generate_question, \n",
        "  inputs=[context,radiobutton], \n",
        "  outputs=output)\n",
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://16479.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://16479.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f463e50fad0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Musk tweeted that his electric vehicle-making company tesla will not accept payments in bitcoin because of environmental concerns. He also said that\n",
            "the company was working with developers of dogecoin to improve system transaction efficiency. The world's largest cryptocurrency hit a two-month low,\n",
            "while doge coin rallied by about 20 percent. Musk has in recent months often tweeted in support of crypto, but rarely for bitcoin.\n",
            "keywords unsummarized:  ['elon musk', 'bitcoin', 'dogecoin', 'statements', 'tesla', 'tweets', 'cryptocurrency', 'vehicle', 'musk', 'system transaction efficiency', 'currency market', 'month low', 'fuels', 'company', 'world']\n",
            "keywords_found in summarized:  ['dogecoin', 'month low', 'world', 'tesla', 'company', 'system transaction efficiency', 'vehicle', 'cryptocurrency', 'musk', 'bitcoin']\n",
            "\n",
            "\n",
            "Noun phrases ['bitcoin', 'dogecoin', 'tesla', 'cryptocurrency']\n",
            "word  Bitcoin\n",
            "PERSON\n",
            "Similar  ['Litecoin', 'Bitcoins', 'Dogecoin', 'Bitcoin', 'Coinbase']\n",
            "distractors  ['Dogecoin', 'Coinbase']\n",
            "word  Dogecoin\n",
            "PERSON\n",
            "Similar  ['Litecoin', 'Bitcoin', 'Reddcoin', 'Blackcoin']\n",
            "distractors  ['Bitcoin', 'Reddcoin', 'Blackcoin']\n",
            "word  Tesla\n",
            "ORG\n",
            "Similar  ['Musk', 'Toyota', 'Nissan', 'Telsa', 'Tesla Motors', 'Prius']\n",
            "distractors  ['Toyota', 'Nissan', 'Tesla Motors', 'Prius']\n",
            "word  Cryptocurrency\n",
            "NOUN\n",
            "Similar  ['Cryptocurrency', 'Digital Currency', 'Bitcoin', 'Cryptocurrencies', 'Blockchain', 'Cryptocurrencies', 'Crypto Currency', 'Crypto', 'Blockchain Technology', 'Crypto-Currencies', 'Bitcoin', 'Crypto-Currency', 'Bitcoin', 'Digital Currencies', 'Crypto', 'Trustless', 'Cryptos', 'Bitcoin Technology', 'Smart Contracts', 'Ethereum', 'Fiat Money', 'Blockchain Technology', 'Altcoin', 'Bitreserve', 'Crypto World', 'Bitcoins', 'Bitcoin World', 'Electronic Money']\n",
            "distractors  ['Digital Currency', 'Bitcoin', 'Blockchain', 'Crypto', 'Blockchain Technology', 'Trustless', 'Smart Contracts', 'Ethereum', 'Fiat Money', 'Bitreserve', 'Crypto World', 'Bitcoin World', 'Electronic Money']\n",
            "A lion lay asleep in the forest, his great head resting on his paws. The timid little mouse ran across the lion's nose and begged him to let him go.\n",
            "\"please let me go and some day i will surely repay you,\" said the mouse. He was generous and finally let the mouse go; some days later, while stalking\n",
            "his prey, the lion was caught in an angry net.\n",
            "keywords unsummarized:  ['lion', 'mouse', 'forest', 'net', 'paws', 'day', 'hunter', 'toils', 'roaring', 'nose', 'voice', 'prey', 'nap', 'head', 'creature']\n",
            "keywords_found in summarized:  ['head', 'prey', 'forest', 'nose', 'paws', 'day', 'mouse', 'lion', 'net']\n",
            "\n",
            "\n",
            "Noun phrases ['lion', 'mouse', 'forest', 'net']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-6cf4c0dcc3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mradiobutton\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   outputs=output)\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 7min 57s (started: 2021-05-20 17:18:53 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}